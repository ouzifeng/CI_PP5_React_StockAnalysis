{"ast":null,"code":"'use strict';\n\nvar __createBinding = this && this.__createBinding || (Object.create ? function (o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  var desc = Object.getOwnPropertyDescriptor(m, k);\n  if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n    desc = {\n      enumerable: true,\n      get: function () {\n        return m[k];\n      }\n    };\n  }\n  Object.defineProperty(o, k2, desc);\n} : function (o, m, k, k2) {\n  if (k2 === undefined) k2 = k;\n  o[k2] = m[k];\n});\nvar __setModuleDefault = this && this.__setModuleDefault || (Object.create ? function (o, v) {\n  Object.defineProperty(o, \"default\", {\n    enumerable: true,\n    value: v\n  });\n} : function (o, v) {\n  o[\"default\"] = v;\n});\nvar __importStar = this && this.__importStar || function (mod) {\n  if (mod && mod.__esModule) return mod;\n  var result = {};\n  if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n  __setModuleDefault(result, mod);\n  return result;\n};\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.Json2Csv = void 0;\nconst doc_path_1 = require(\"doc-path\");\nconst deeks_1 = require(\"deeks\");\nconst constants_1 = require(\"./constants\");\nconst utils = __importStar(require(\"./utils\"));\nconst Json2Csv = function (options) {\n  const wrapDelimiterCheckRegex = new RegExp(options.delimiter.wrap, 'g'),\n    crlfSearchRegex = /\\r?\\n|\\r/,\n    customValueParser = options.parseValue && typeof options.parseValue === 'function' ? options.parseValue : null,\n    expandingWithoutUnwinding = options.expandArrayObjects && !options.unwindArrays,\n    deeksOptions = {\n      expandNestedObjects: options.expandNestedObjects,\n      expandArrayObjects: expandingWithoutUnwinding,\n      ignoreEmptyArraysWhenExpanding: expandingWithoutUnwinding,\n      escapeNestedDots: true\n    };\n  /** HEADER FIELD FUNCTIONS **/\n  /**\n   * Returns the list of data field names of all documents in the provided list\n   */\n  function getFieldNameList(data) {\n    // If keys weren't specified, then we'll use the list of keys generated by the deeks module\n    return (0, deeks_1.deepKeysFromList)(data, deeksOptions);\n  }\n  /**\n   * Processes the schemas by checking for schema differences, if so desired.\n   * If schema differences are not to be checked, then it resolves the unique\n   * list of field names.\n   */\n  function processSchemas(documentSchemas) {\n    // If the user wants to check for the same schema (regardless of schema ordering)\n    if (options.checkSchemaDifferences) {\n      return checkSchemaDifferences(documentSchemas);\n    } else {\n      // Otherwise, we do not care if the schemas are different, so we should get the unique list of keys\n      const uniqueFieldNames = utils.unique(utils.flatten(documentSchemas));\n      return uniqueFieldNames;\n    }\n  }\n  /**\n   * This function performs the schema difference check, if the user specifies that it should be checked.\n   * If there are no field names, then there are no differences.\n   * Otherwise, we get the first schema and the remaining list of schemas\n   */\n  function checkSchemaDifferences(documentSchemas) {\n    // have multiple documents - ensure only one schema (regardless of field ordering)\n    const firstDocSchema = documentSchemas[0],\n      restOfDocumentSchemas = documentSchemas.slice(1),\n      schemaDifferences = computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas);\n    // If there are schema inconsistencies, throw a schema not the same error\n    if (schemaDifferences) {\n      throw new Error(constants_1.errors.json2csv.notSameSchema);\n    }\n    return firstDocSchema;\n  }\n  /**\n   * Computes the number of schema differences\n   */\n  function computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas) {\n    return restOfDocumentSchemas.reduce((schemaDifferences, documentSchema) => {\n      // If there is a difference between the schemas, increment the counter of schema inconsistencies\n      const numberOfDifferences = utils.computeSchemaDifferences(firstDocSchema, documentSchema).length;\n      return numberOfDifferences > 0 ? schemaDifferences + 1 : schemaDifferences;\n    }, 0);\n  }\n  /**\n   * If so specified, this filters the detected key paths to exclude any keys that have been specified\n   */\n  function filterExcludedKeys(keyPaths) {\n    if (options.excludeKeys) {\n      return keyPaths.filter(keyPath => {\n        return !options.excludeKeys.includes(keyPath);\n      });\n    }\n    return keyPaths;\n  }\n  /**\n   * If so specified, this sorts the header field names alphabetically\n   */\n  function sortHeaderFields(fieldNames) {\n    if (options.sortHeader && typeof options.sortHeader === 'function') {\n      return fieldNames.sort(options.sortHeader);\n    } else if (options.sortHeader) {\n      return fieldNames.sort();\n    }\n    return fieldNames;\n  }\n  /**\n   * Trims the header fields, if the user desires them to be trimmed.\n   */\n  function trimHeaderFields(params) {\n    if (options.trimHeaderFields) {\n      params.headerFields = params.headerFields.map(field => field.split('.').map(component => component.trim()).join('.'));\n    }\n    return params;\n  }\n  /**\n   * Wrap the headings, if desired by the user.\n   */\n  function wrapHeaderFields(params) {\n    // only perform this if we are actually prepending the header\n    if (options.prependHeader) {\n      params.headerFields = params.headerFields.map(function (headingKey) {\n        return wrapFieldValueIfNecessary(headingKey);\n      });\n    }\n    return params;\n  }\n  /**\n   * Generates the CSV header string by joining the headerFields by the field delimiter\n   */\n  function generateCsvHeader(params) {\n    // #185 - generate a keys list to avoid finding native Map() methods\n    const fieldTitleMapKeys = Object.keys(options.fieldTitleMap);\n    params.header = params.headerFields.map(function (field) {\n      const headerKey = fieldTitleMapKeys.includes(field) ? options.fieldTitleMap[field] : field;\n      return wrapFieldValueIfNecessary(headerKey);\n    }).join(options.delimiter.field);\n    return params;\n  }\n  function convertKeysToHeaderFields() {\n    if (!options.keys) return [];\n    return options.keys.map(key => {\n      if (typeof key === 'object' && 'field' in key) {\n        options.fieldTitleMap[key.field] = key.title ?? key.field;\n        return key.field;\n      }\n      return key;\n    });\n  }\n  /**\n   * Retrieve the headings for all documents and return it.\n   * This checks that all documents have the same schema.\n   */\n  function retrieveHeaderFields(data) {\n    const keyStrings = convertKeysToHeaderFields();\n    if (options.keys) {\n      options.keys = keyStrings;\n      if (!options.unwindArrays) {\n        const filtered = filterExcludedKeys(keyStrings);\n        return sortHeaderFields(filtered);\n      }\n    }\n    const fieldNames = getFieldNameList(data);\n    const processed = processSchemas(fieldNames);\n    const filtered = filterExcludedKeys(processed);\n    return sortHeaderFields(filtered);\n  }\n  /** RECORD FIELD FUNCTIONS **/\n  /**\n   * Unwinds objects in arrays within record objects if the user specifies the\n   * expandArrayObjects option. If not specified, this passes the params\n   * argument through to the next function in the promise chain.\n   *\n   * The `finalPass` parameter is used to trigger one last pass to ensure no more\n   * arrays need to be expanded\n   */\n  function unwindRecordsIfNecessary(params, finalPass = false) {\n    if (options.unwindArrays) {\n      const originalRecordsLength = params.records.length;\n      // Unwind each of the documents at the given headerField\n      params.headerFields.forEach(headerField => {\n        params.records = utils.unwind(params.records, headerField);\n      });\n      const headerFields = retrieveHeaderFields(params.records);\n      params.headerFields = headerFields;\n      // If we were able to unwind more arrays, then try unwinding again...\n      if (originalRecordsLength !== params.records.length) {\n        return unwindRecordsIfNecessary(params);\n      }\n      // Otherwise, we didn't unwind any additional arrays, so continue...\n      // Run a final time in case the earlier unwinding exposed additional\n      // arrays to unwind...\n      if (!finalPass) {\n        return unwindRecordsIfNecessary(params, true);\n      }\n      // If keys were provided, set the headerFields back to the provided keys after unwinding:\n      if (options.keys) {\n        const userSelectedFields = convertKeysToHeaderFields();\n        params.headerFields = filterExcludedKeys(userSelectedFields);\n      }\n      return params;\n    }\n    return params;\n  }\n  /**\n   * Main function which handles the processing of a record, or document to be converted to CSV format\n   * This function specifies and performs the necessary operations in the necessary order\n   * in order to obtain the data and convert it to CSV form while maintaining RFC 4180 compliance.\n   * * Order of operations:\n   * - Get fields from provided key list (as array of actual values)\n   * - Convert the values to csv/string representation [possible option here for custom converters?]\n   * - Trim fields\n   * - Determine if they need to be wrapped (& wrap if necessary)\n   * - Combine values for each line (by joining by field delimiter)\n   */\n  function processRecords(params) {\n    params.recordString = params.records.map(record => {\n      // Retrieve data for each of the headerFields from this record\n      const recordFieldData = retrieveRecordFieldData(record, params.headerFields),\n        // Process the data in this record and return the\n        processedRecordData = recordFieldData.map(fieldValue => {\n          fieldValue = trimRecordFieldValue(fieldValue);\n          fieldValue = preventCsvInjection(fieldValue);\n          let stringified = customValueParser ? customValueParser(fieldValue, recordFieldValueToString) : recordFieldValueToString(fieldValue);\n          stringified = wrapFieldValueIfNecessary(stringified);\n          return stringified;\n        });\n      // Join the record data by the field delimiter\n      return generateCsvRowFromRecord(processedRecordData);\n    }).join(options.delimiter.eol);\n    return params;\n  }\n  /**\n   * Helper function intended to process *just* array values when the expandArrayObjects setting is set to true\n   */\n  function processRecordFieldDataForExpandedArrayObject(recordFieldValue) {\n    const filteredRecordFieldValue = utils.removeEmptyFields(recordFieldValue);\n    // If we have an array and it's either empty of full of empty values, then use an empty value representation\n    if (!recordFieldValue.length || !filteredRecordFieldValue.length) {\n      return options.emptyFieldValue || '';\n    } else if (filteredRecordFieldValue.length === 1) {\n      // Otherwise, we have an array of actual values...\n      // Since we are expanding array objects, we will want to key in on values of objects.\n      return filteredRecordFieldValue[0]; // Extract the single value in the array\n    }\n    return recordFieldValue;\n  }\n  /**\n   * Gets all field values from a particular record for the given list of fields\n   */\n  function retrieveRecordFieldData(record, fields) {\n    const recordValues = [];\n    fields.forEach(field => {\n      let recordFieldValue = (0, doc_path_1.evaluatePath)(record, field);\n      if (!utils.isUndefined(options.emptyFieldValue) && utils.isEmptyField(recordFieldValue)) {\n        recordFieldValue = options.emptyFieldValue;\n      } else if (options.expandArrayObjects && Array.isArray(recordFieldValue)) {\n        recordFieldValue = processRecordFieldDataForExpandedArrayObject(recordFieldValue);\n      }\n      recordValues.push(recordFieldValue);\n    });\n    return recordValues;\n  }\n  /**\n   * Converts a record field value to its string representation\n   */\n  function recordFieldValueToString(fieldValue) {\n    const isDate = fieldValue instanceof Date; // store to avoid checking twice\n    if (fieldValue === null || Array.isArray(fieldValue) || typeof fieldValue === 'object' && !isDate) {\n      return JSON.stringify(fieldValue);\n    } else if (typeof fieldValue === 'undefined') {\n      return 'undefined';\n    } else if (isDate && options.useDateIso8601Format) {\n      return fieldValue.toISOString();\n    } else {\n      return !options.useLocaleFormat ? fieldValue.toString() : fieldValue.toLocaleString();\n    }\n  }\n  /**\n   * Trims the record field value, if specified by the user's provided options\n   */\n  function trimRecordFieldValue(fieldValue) {\n    if (options.trimFieldValues) {\n      if (Array.isArray(fieldValue)) {\n        return fieldValue.map(trimRecordFieldValue);\n      } else if (typeof fieldValue === 'string') {\n        return fieldValue.trim();\n      }\n      return fieldValue;\n    }\n    return fieldValue;\n  }\n  /**\n   * Prevent CSV injection on strings if specified by the user's provided options.\n   * Mitigation will be done by ensuring that the first character doesn't being with:\n   * Equals (=), Plus (+), Minus (-), At (@), Tab (0x09), Carriage return (0x0D).\n   * More info: https://owasp.org/www-community/attacks/CSV_Injection\n   */\n  function preventCsvInjection(fieldValue) {\n    if (options.preventCsvInjection) {\n      if (Array.isArray(fieldValue)) {\n        return fieldValue.map(preventCsvInjection);\n      } else if (typeof fieldValue === 'string' && !utils.isNumber(fieldValue)) {\n        return fieldValue.replace(/^[=+\\-@\\t\\r]+/g, '');\n      }\n      return fieldValue;\n    }\n    return fieldValue;\n  }\n  /**\n   * Escapes quotation marks in the field value, if necessary, and appropriately\n   * wraps the record field value if it contains a comma (field delimiter),\n   * quotation mark (wrap delimiter), or a line break (CRLF)\n   */\n  function wrapFieldValueIfNecessary(fieldValue) {\n    const wrapDelimiter = options.delimiter.wrap;\n    // eg. includes quotation marks (default delimiter)\n    if (fieldValue.includes(options.delimiter.wrap)) {\n      // add an additional quotation mark before each quotation mark appearing in the field value\n      fieldValue = fieldValue.replace(wrapDelimiterCheckRegex, wrapDelimiter + wrapDelimiter);\n    }\n    // if the field contains a comma (field delimiter), quotation mark (wrap delimiter), line break, or CRLF\n    //   then enclose it in quotation marks (wrap delimiter)\n    if (fieldValue.includes(options.delimiter.field) || fieldValue.includes(options.delimiter.wrap) || fieldValue.match(crlfSearchRegex) || options.wrapBooleans && (fieldValue === 'true' || fieldValue === 'false')) {\n      // wrap the field's value in a wrap delimiter (quotation marks by default)\n      fieldValue = wrapDelimiter + fieldValue + wrapDelimiter;\n    }\n    return fieldValue;\n  }\n  /**\n   * Generates the CSV record string by joining the field values together by the field delimiter\n   */\n  function generateCsvRowFromRecord(recordFieldValues) {\n    return recordFieldValues.join(options.delimiter.field);\n  }\n  /** CSV COMPONENT COMBINER/FINAL PROCESSOR **/\n  /**\n   * Performs the final CSV construction by combining the fields in the appropriate\n   * order depending on the provided options values and sends the generated CSV\n   * back to the user\n   */\n  function generateCsvFromComponents(params) {\n    const header = params.header,\n      records = params.recordString,\n      // If we are prepending the header, then add an EOL, otherwise just return the records\n      csv = (options.excelBOM ? constants_1.excelBOM : '') + (options.prependHeader ? header + options.delimiter.eol : '') + records;\n    return csv;\n  }\n  /** MAIN CONVERTER FUNCTION **/\n  /**\n   * Internally exported json2csv function\n   */\n  function convert(data) {\n    // Single document, not an array\n    if (utils.isObject(data) && !data.length) {\n      data = [data]; // Convert to an array of the given document\n    }\n    // Retrieve the heading and then generate the CSV with the keys that are identified\n    const headerFields = {\n      headerFields: retrieveHeaderFields(data),\n      records: data,\n      header: '',\n      recordString: ''\n    };\n    const unwinded = unwindRecordsIfNecessary(headerFields);\n    const processed = processRecords(unwinded);\n    const wrapped = wrapHeaderFields(processed);\n    const trimmed = trimHeaderFields(wrapped);\n    const generated = generateCsvHeader(trimmed);\n    return generateCsvFromComponents(generated);\n  }\n  return {\n    convert\n  };\n};\nexports.Json2Csv = Json2Csv;","map":{"version":3,"names":["__createBinding","Object","create","o","m","k","k2","undefined","desc","getOwnPropertyDescriptor","__esModule","writable","configurable","enumerable","get","defineProperty","__setModuleDefault","v","value","__importStar","mod","result","prototype","hasOwnProperty","call","exports","Json2Csv","doc_path_1","require","deeks_1","constants_1","utils","options","wrapDelimiterCheckRegex","RegExp","delimiter","wrap","crlfSearchRegex","customValueParser","parseValue","expandingWithoutUnwinding","expandArrayObjects","unwindArrays","deeksOptions","expandNestedObjects","ignoreEmptyArraysWhenExpanding","escapeNestedDots","getFieldNameList","data","deepKeysFromList","processSchemas","documentSchemas","checkSchemaDifferences","uniqueFieldNames","unique","flatten","firstDocSchema","restOfDocumentSchemas","slice","schemaDifferences","computeNumberOfSchemaDifferences","Error","errors","json2csv","notSameSchema","reduce","documentSchema","numberOfDifferences","computeSchemaDifferences","length","filterExcludedKeys","keyPaths","excludeKeys","filter","keyPath","includes","sortHeaderFields","fieldNames","sortHeader","sort","trimHeaderFields","params","headerFields","map","field","split","component","trim","join","wrapHeaderFields","prependHeader","headingKey","wrapFieldValueIfNecessary","generateCsvHeader","fieldTitleMapKeys","keys","fieldTitleMap","header","headerKey","convertKeysToHeaderFields","key","title","retrieveHeaderFields","keyStrings","filtered","processed","unwindRecordsIfNecessary","finalPass","originalRecordsLength","records","forEach","headerField","unwind","userSelectedFields","processRecords","recordString","record","recordFieldData","retrieveRecordFieldData","processedRecordData","fieldValue","trimRecordFieldValue","preventCsvInjection","stringified","recordFieldValueToString","generateCsvRowFromRecord","eol","processRecordFieldDataForExpandedArrayObject","recordFieldValue","filteredRecordFieldValue","removeEmptyFields","emptyFieldValue","fields","recordValues","evaluatePath","isUndefined","isEmptyField","Array","isArray","push","isDate","Date","JSON","stringify","useDateIso8601Format","toISOString","useLocaleFormat","toString","toLocaleString","trimFieldValues","isNumber","replace","wrapDelimiter","match","wrapBooleans","recordFieldValues","generateCsvFromComponents","csv","excelBOM","convert","isObject","unwinded","wrapped","trimmed","generated"],"sources":["C:/Users/David/Desktop/Websites/stocks/frontend/node_modules/json-2-csv/lib/json2csv.js"],"sourcesContent":["'use strict';\nvar __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    var desc = Object.getOwnPropertyDescriptor(m, k);\n    if (!desc || (\"get\" in desc ? !m.__esModule : desc.writable || desc.configurable)) {\n      desc = { enumerable: true, get: function() { return m[k]; } };\n    }\n    Object.defineProperty(o, k2, desc);\n}) : (function(o, m, k, k2) {\n    if (k2 === undefined) k2 = k;\n    o[k2] = m[k];\n}));\nvar __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {\n    Object.defineProperty(o, \"default\", { enumerable: true, value: v });\n}) : function(o, v) {\n    o[\"default\"] = v;\n});\nvar __importStar = (this && this.__importStar) || function (mod) {\n    if (mod && mod.__esModule) return mod;\n    var result = {};\n    if (mod != null) for (var k in mod) if (k !== \"default\" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);\n    __setModuleDefault(result, mod);\n    return result;\n};\nObject.defineProperty(exports, \"__esModule\", { value: true });\nexports.Json2Csv = void 0;\nconst doc_path_1 = require(\"doc-path\");\nconst deeks_1 = require(\"deeks\");\nconst constants_1 = require(\"./constants\");\nconst utils = __importStar(require(\"./utils\"));\nconst Json2Csv = function (options) {\n    const wrapDelimiterCheckRegex = new RegExp(options.delimiter.wrap, 'g'), crlfSearchRegex = /\\r?\\n|\\r/, customValueParser = options.parseValue && typeof options.parseValue === 'function' ? options.parseValue : null, expandingWithoutUnwinding = options.expandArrayObjects && !options.unwindArrays, deeksOptions = {\n        expandNestedObjects: options.expandNestedObjects,\n        expandArrayObjects: expandingWithoutUnwinding,\n        ignoreEmptyArraysWhenExpanding: expandingWithoutUnwinding,\n        escapeNestedDots: true\n    };\n    /** HEADER FIELD FUNCTIONS **/\n    /**\n     * Returns the list of data field names of all documents in the provided list\n     */\n    function getFieldNameList(data) {\n        // If keys weren't specified, then we'll use the list of keys generated by the deeks module\n        return (0, deeks_1.deepKeysFromList)(data, deeksOptions);\n    }\n    /**\n     * Processes the schemas by checking for schema differences, if so desired.\n     * If schema differences are not to be checked, then it resolves the unique\n     * list of field names.\n     */\n    function processSchemas(documentSchemas) {\n        // If the user wants to check for the same schema (regardless of schema ordering)\n        if (options.checkSchemaDifferences) {\n            return checkSchemaDifferences(documentSchemas);\n        }\n        else {\n            // Otherwise, we do not care if the schemas are different, so we should get the unique list of keys\n            const uniqueFieldNames = utils.unique(utils.flatten(documentSchemas));\n            return uniqueFieldNames;\n        }\n    }\n    /**\n     * This function performs the schema difference check, if the user specifies that it should be checked.\n     * If there are no field names, then there are no differences.\n     * Otherwise, we get the first schema and the remaining list of schemas\n     */\n    function checkSchemaDifferences(documentSchemas) {\n        // have multiple documents - ensure only one schema (regardless of field ordering)\n        const firstDocSchema = documentSchemas[0], restOfDocumentSchemas = documentSchemas.slice(1), schemaDifferences = computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas);\n        // If there are schema inconsistencies, throw a schema not the same error\n        if (schemaDifferences) {\n            throw new Error(constants_1.errors.json2csv.notSameSchema);\n        }\n        return firstDocSchema;\n    }\n    /**\n     * Computes the number of schema differences\n     */\n    function computeNumberOfSchemaDifferences(firstDocSchema, restOfDocumentSchemas) {\n        return restOfDocumentSchemas.reduce((schemaDifferences, documentSchema) => {\n            // If there is a difference between the schemas, increment the counter of schema inconsistencies\n            const numberOfDifferences = utils.computeSchemaDifferences(firstDocSchema, documentSchema).length;\n            return numberOfDifferences > 0\n                ? schemaDifferences + 1\n                : schemaDifferences;\n        }, 0);\n    }\n    /**\n     * If so specified, this filters the detected key paths to exclude any keys that have been specified\n     */\n    function filterExcludedKeys(keyPaths) {\n        if (options.excludeKeys) {\n            return keyPaths.filter((keyPath) => {\n                return !options.excludeKeys.includes(keyPath);\n            });\n        }\n        return keyPaths;\n    }\n    /**\n     * If so specified, this sorts the header field names alphabetically\n     */\n    function sortHeaderFields(fieldNames) {\n        if (options.sortHeader && typeof options.sortHeader === 'function') {\n            return fieldNames.sort(options.sortHeader);\n        }\n        else if (options.sortHeader) {\n            return fieldNames.sort();\n        }\n        return fieldNames;\n    }\n    /**\n     * Trims the header fields, if the user desires them to be trimmed.\n     */\n    function trimHeaderFields(params) {\n        if (options.trimHeaderFields) {\n            params.headerFields = params.headerFields.map((field) => field.split('.')\n                .map((component) => component.trim())\n                .join('.'));\n        }\n        return params;\n    }\n    /**\n     * Wrap the headings, if desired by the user.\n     */\n    function wrapHeaderFields(params) {\n        // only perform this if we are actually prepending the header\n        if (options.prependHeader) {\n            params.headerFields = params.headerFields.map(function (headingKey) {\n                return wrapFieldValueIfNecessary(headingKey);\n            });\n        }\n        return params;\n    }\n    /**\n     * Generates the CSV header string by joining the headerFields by the field delimiter\n     */\n    function generateCsvHeader(params) {\n        // #185 - generate a keys list to avoid finding native Map() methods\n        const fieldTitleMapKeys = Object.keys(options.fieldTitleMap);\n        params.header = params.headerFields\n            .map(function (field) {\n            const headerKey = fieldTitleMapKeys.includes(field) ? options.fieldTitleMap[field] : field;\n            return wrapFieldValueIfNecessary(headerKey);\n        })\n            .join(options.delimiter.field);\n        return params;\n    }\n    function convertKeysToHeaderFields() {\n        if (!options.keys)\n            return [];\n        return options.keys.map((key) => {\n            if (typeof key === 'object' && 'field' in key) {\n                options.fieldTitleMap[key.field] = key.title ?? key.field;\n                return key.field;\n            }\n            return key;\n        });\n    }\n    /**\n     * Retrieve the headings for all documents and return it.\n     * This checks that all documents have the same schema.\n     */\n    function retrieveHeaderFields(data) {\n        const keyStrings = convertKeysToHeaderFields();\n        if (options.keys) {\n            options.keys = keyStrings;\n            if (!options.unwindArrays) {\n                const filtered = filterExcludedKeys(keyStrings);\n                return sortHeaderFields(filtered);\n            }\n        }\n        const fieldNames = getFieldNameList(data);\n        const processed = processSchemas(fieldNames);\n        const filtered = filterExcludedKeys(processed);\n        return sortHeaderFields(filtered);\n    }\n    /** RECORD FIELD FUNCTIONS **/\n    /**\n     * Unwinds objects in arrays within record objects if the user specifies the\n     * expandArrayObjects option. If not specified, this passes the params\n     * argument through to the next function in the promise chain.\n     *\n     * The `finalPass` parameter is used to trigger one last pass to ensure no more\n     * arrays need to be expanded\n     */\n    function unwindRecordsIfNecessary(params, finalPass = false) {\n        if (options.unwindArrays) {\n            const originalRecordsLength = params.records.length;\n            // Unwind each of the documents at the given headerField\n            params.headerFields.forEach((headerField) => {\n                params.records = utils.unwind(params.records, headerField);\n            });\n            const headerFields = retrieveHeaderFields(params.records);\n            params.headerFields = headerFields;\n            // If we were able to unwind more arrays, then try unwinding again...\n            if (originalRecordsLength !== params.records.length) {\n                return unwindRecordsIfNecessary(params);\n            }\n            // Otherwise, we didn't unwind any additional arrays, so continue...\n            // Run a final time in case the earlier unwinding exposed additional\n            // arrays to unwind...\n            if (!finalPass) {\n                return unwindRecordsIfNecessary(params, true);\n            }\n            // If keys were provided, set the headerFields back to the provided keys after unwinding:\n            if (options.keys) {\n                const userSelectedFields = convertKeysToHeaderFields();\n                params.headerFields = filterExcludedKeys(userSelectedFields);\n            }\n            return params;\n        }\n        return params;\n    }\n    /**\n     * Main function which handles the processing of a record, or document to be converted to CSV format\n     * This function specifies and performs the necessary operations in the necessary order\n     * in order to obtain the data and convert it to CSV form while maintaining RFC 4180 compliance.\n     * * Order of operations:\n     * - Get fields from provided key list (as array of actual values)\n     * - Convert the values to csv/string representation [possible option here for custom converters?]\n     * - Trim fields\n     * - Determine if they need to be wrapped (& wrap if necessary)\n     * - Combine values for each line (by joining by field delimiter)\n     */\n    function processRecords(params) {\n        params.recordString = params.records.map((record) => {\n            // Retrieve data for each of the headerFields from this record\n            const recordFieldData = retrieveRecordFieldData(record, params.headerFields), \n            // Process the data in this record and return the\n            processedRecordData = recordFieldData.map((fieldValue) => {\n                fieldValue = trimRecordFieldValue(fieldValue);\n                fieldValue = preventCsvInjection(fieldValue);\n                let stringified = customValueParser ? customValueParser(fieldValue, recordFieldValueToString) : recordFieldValueToString(fieldValue);\n                stringified = wrapFieldValueIfNecessary(stringified);\n                return stringified;\n            });\n            // Join the record data by the field delimiter\n            return generateCsvRowFromRecord(processedRecordData);\n        }).join(options.delimiter.eol);\n        return params;\n    }\n    /**\n     * Helper function intended to process *just* array values when the expandArrayObjects setting is set to true\n     */\n    function processRecordFieldDataForExpandedArrayObject(recordFieldValue) {\n        const filteredRecordFieldValue = utils.removeEmptyFields(recordFieldValue);\n        // If we have an array and it's either empty of full of empty values, then use an empty value representation\n        if (!recordFieldValue.length || !filteredRecordFieldValue.length) {\n            return options.emptyFieldValue || '';\n        }\n        else if (filteredRecordFieldValue.length === 1) {\n            // Otherwise, we have an array of actual values...\n            // Since we are expanding array objects, we will want to key in on values of objects.\n            return filteredRecordFieldValue[0]; // Extract the single value in the array\n        }\n        return recordFieldValue;\n    }\n    /**\n     * Gets all field values from a particular record for the given list of fields\n     */\n    function retrieveRecordFieldData(record, fields) {\n        const recordValues = [];\n        fields.forEach((field) => {\n            let recordFieldValue = (0, doc_path_1.evaluatePath)(record, field);\n            if (!utils.isUndefined(options.emptyFieldValue) && utils.isEmptyField(recordFieldValue)) {\n                recordFieldValue = options.emptyFieldValue;\n            }\n            else if (options.expandArrayObjects && Array.isArray(recordFieldValue)) {\n                recordFieldValue = processRecordFieldDataForExpandedArrayObject(recordFieldValue);\n            }\n            recordValues.push(recordFieldValue);\n        });\n        return recordValues;\n    }\n    /**\n     * Converts a record field value to its string representation\n     */\n    function recordFieldValueToString(fieldValue) {\n        const isDate = fieldValue instanceof Date; // store to avoid checking twice\n        if (fieldValue === null || Array.isArray(fieldValue) || typeof fieldValue === 'object' && !isDate) {\n            return JSON.stringify(fieldValue);\n        }\n        else if (typeof fieldValue === 'undefined') {\n            return 'undefined';\n        }\n        else if (isDate && options.useDateIso8601Format) {\n            return fieldValue.toISOString();\n        }\n        else {\n            return !options.useLocaleFormat ? fieldValue.toString() : fieldValue.toLocaleString();\n        }\n    }\n    /**\n     * Trims the record field value, if specified by the user's provided options\n     */\n    function trimRecordFieldValue(fieldValue) {\n        if (options.trimFieldValues) {\n            if (Array.isArray(fieldValue)) {\n                return fieldValue.map(trimRecordFieldValue);\n            }\n            else if (typeof fieldValue === 'string') {\n                return fieldValue.trim();\n            }\n            return fieldValue;\n        }\n        return fieldValue;\n    }\n    /**\n     * Prevent CSV injection on strings if specified by the user's provided options.\n     * Mitigation will be done by ensuring that the first character doesn't being with:\n     * Equals (=), Plus (+), Minus (-), At (@), Tab (0x09), Carriage return (0x0D).\n     * More info: https://owasp.org/www-community/attacks/CSV_Injection\n     */\n    function preventCsvInjection(fieldValue) {\n        if (options.preventCsvInjection) {\n            if (Array.isArray(fieldValue)) {\n                return fieldValue.map(preventCsvInjection);\n            }\n            else if (typeof fieldValue === 'string' && !utils.isNumber(fieldValue)) {\n                return fieldValue.replace(/^[=+\\-@\\t\\r]+/g, '');\n            }\n            return fieldValue;\n        }\n        return fieldValue;\n    }\n    /**\n     * Escapes quotation marks in the field value, if necessary, and appropriately\n     * wraps the record field value if it contains a comma (field delimiter),\n     * quotation mark (wrap delimiter), or a line break (CRLF)\n     */\n    function wrapFieldValueIfNecessary(fieldValue) {\n        const wrapDelimiter = options.delimiter.wrap;\n        // eg. includes quotation marks (default delimiter)\n        if (fieldValue.includes(options.delimiter.wrap)) {\n            // add an additional quotation mark before each quotation mark appearing in the field value\n            fieldValue = fieldValue.replace(wrapDelimiterCheckRegex, wrapDelimiter + wrapDelimiter);\n        }\n        // if the field contains a comma (field delimiter), quotation mark (wrap delimiter), line break, or CRLF\n        //   then enclose it in quotation marks (wrap delimiter)\n        if (fieldValue.includes(options.delimiter.field) ||\n            fieldValue.includes(options.delimiter.wrap) ||\n            fieldValue.match(crlfSearchRegex) ||\n            options.wrapBooleans && (fieldValue === 'true' || fieldValue === 'false')) {\n            // wrap the field's value in a wrap delimiter (quotation marks by default)\n            fieldValue = wrapDelimiter + fieldValue + wrapDelimiter;\n        }\n        return fieldValue;\n    }\n    /**\n     * Generates the CSV record string by joining the field values together by the field delimiter\n     */\n    function generateCsvRowFromRecord(recordFieldValues) {\n        return recordFieldValues.join(options.delimiter.field);\n    }\n    /** CSV COMPONENT COMBINER/FINAL PROCESSOR **/\n    /**\n     * Performs the final CSV construction by combining the fields in the appropriate\n     * order depending on the provided options values and sends the generated CSV\n     * back to the user\n     */\n    function generateCsvFromComponents(params) {\n        const header = params.header, records = params.recordString, \n        // If we are prepending the header, then add an EOL, otherwise just return the records\n        csv = (options.excelBOM ? constants_1.excelBOM : '') +\n            (options.prependHeader ? header + options.delimiter.eol : '') +\n            records;\n        return csv;\n    }\n    /** MAIN CONVERTER FUNCTION **/\n    /**\n     * Internally exported json2csv function\n     */\n    function convert(data) {\n        // Single document, not an array\n        if (utils.isObject(data) && !data.length) {\n            data = [data]; // Convert to an array of the given document\n        }\n        // Retrieve the heading and then generate the CSV with the keys that are identified\n        const headerFields = {\n            headerFields: retrieveHeaderFields(data),\n            records: data,\n            header: '',\n            recordString: '',\n        };\n        const unwinded = unwindRecordsIfNecessary(headerFields);\n        const processed = processRecords(unwinded);\n        const wrapped = wrapHeaderFields(processed);\n        const trimmed = trimHeaderFields(wrapped);\n        const generated = generateCsvHeader(trimmed);\n        return generateCsvFromComponents(generated);\n    }\n    return {\n        convert,\n    };\n};\nexports.Json2Csv = Json2Csv;\n"],"mappings":"AAAA,YAAY;;AACZ,IAAIA,eAAe,GAAI,IAAI,IAAI,IAAI,CAACA,eAAe,KAAMC,MAAM,CAACC,MAAM,GAAI,UAASC,CAAC,EAAEC,CAAC,EAAEC,CAAC,EAAEC,EAAE,EAAE;EAC5F,IAAIA,EAAE,KAAKC,SAAS,EAAED,EAAE,GAAGD,CAAC;EAC5B,IAAIG,IAAI,GAAGP,MAAM,CAACQ,wBAAwB,CAACL,CAAC,EAAEC,CAAC,CAAC;EAChD,IAAI,CAACG,IAAI,KAAK,KAAK,IAAIA,IAAI,GAAG,CAACJ,CAAC,CAACM,UAAU,GAAGF,IAAI,CAACG,QAAQ,IAAIH,IAAI,CAACI,YAAY,CAAC,EAAE;IACjFJ,IAAI,GAAG;MAAEK,UAAU,EAAE,IAAI;MAAEC,GAAG,EAAE,SAAAA,CAAA,EAAW;QAAE,OAAOV,CAAC,CAACC,CAAC,CAAC;MAAE;IAAE,CAAC;EAC/D;EACAJ,MAAM,CAACc,cAAc,CAACZ,CAAC,EAAEG,EAAE,EAAEE,IAAI,CAAC;AACtC,CAAC,GAAK,UAASL,CAAC,EAAEC,CAAC,EAAEC,CAAC,EAAEC,EAAE,EAAE;EACxB,IAAIA,EAAE,KAAKC,SAAS,EAAED,EAAE,GAAGD,CAAC;EAC5BF,CAAC,CAACG,EAAE,CAAC,GAAGF,CAAC,CAACC,CAAC,CAAC;AAChB,CAAE,CAAC;AACH,IAAIW,kBAAkB,GAAI,IAAI,IAAI,IAAI,CAACA,kBAAkB,KAAMf,MAAM,CAACC,MAAM,GAAI,UAASC,CAAC,EAAEc,CAAC,EAAE;EAC3FhB,MAAM,CAACc,cAAc,CAACZ,CAAC,EAAE,SAAS,EAAE;IAAEU,UAAU,EAAE,IAAI;IAAEK,KAAK,EAAED;EAAE,CAAC,CAAC;AACvE,CAAC,GAAI,UAASd,CAAC,EAAEc,CAAC,EAAE;EAChBd,CAAC,CAAC,SAAS,CAAC,GAAGc,CAAC;AACpB,CAAC,CAAC;AACF,IAAIE,YAAY,GAAI,IAAI,IAAI,IAAI,CAACA,YAAY,IAAK,UAAUC,GAAG,EAAE;EAC7D,IAAIA,GAAG,IAAIA,GAAG,CAACV,UAAU,EAAE,OAAOU,GAAG;EACrC,IAAIC,MAAM,GAAG,CAAC,CAAC;EACf,IAAID,GAAG,IAAI,IAAI,EAAE,KAAK,IAAIf,CAAC,IAAIe,GAAG,EAAE,IAAIf,CAAC,KAAK,SAAS,IAAIJ,MAAM,CAACqB,SAAS,CAACC,cAAc,CAACC,IAAI,CAACJ,GAAG,EAAEf,CAAC,CAAC,EAAEL,eAAe,CAACqB,MAAM,EAAED,GAAG,EAAEf,CAAC,CAAC;EACxIW,kBAAkB,CAACK,MAAM,EAAED,GAAG,CAAC;EAC/B,OAAOC,MAAM;AACjB,CAAC;AACDpB,MAAM,CAACc,cAAc,CAACU,OAAO,EAAE,YAAY,EAAE;EAAEP,KAAK,EAAE;AAAK,CAAC,CAAC;AAC7DO,OAAO,CAACC,QAAQ,GAAG,KAAK,CAAC;AACzB,MAAMC,UAAU,GAAGC,OAAO,CAAC,UAAU,CAAC;AACtC,MAAMC,OAAO,GAAGD,OAAO,CAAC,OAAO,CAAC;AAChC,MAAME,WAAW,GAAGF,OAAO,CAAC,aAAa,CAAC;AAC1C,MAAMG,KAAK,GAAGZ,YAAY,CAACS,OAAO,CAAC,SAAS,CAAC,CAAC;AAC9C,MAAMF,QAAQ,GAAG,SAAAA,CAAUM,OAAO,EAAE;EAChC,MAAMC,uBAAuB,GAAG,IAAIC,MAAM,CAACF,OAAO,CAACG,SAAS,CAACC,IAAI,EAAE,GAAG,CAAC;IAAEC,eAAe,GAAG,UAAU;IAAEC,iBAAiB,GAAGN,OAAO,CAACO,UAAU,IAAI,OAAOP,OAAO,CAACO,UAAU,KAAK,UAAU,GAAGP,OAAO,CAACO,UAAU,GAAG,IAAI;IAAEC,yBAAyB,GAAGR,OAAO,CAACS,kBAAkB,IAAI,CAACT,OAAO,CAACU,YAAY;IAAEC,YAAY,GAAG;MACnTC,mBAAmB,EAAEZ,OAAO,CAACY,mBAAmB;MAChDH,kBAAkB,EAAED,yBAAyB;MAC7CK,8BAA8B,EAAEL,yBAAyB;MACzDM,gBAAgB,EAAE;IACtB,CAAC;EACD;EACA;AACJ;AACA;EACI,SAASC,gBAAgBA,CAACC,IAAI,EAAE;IAC5B;IACA,OAAO,CAAC,CAAC,EAAEnB,OAAO,CAACoB,gBAAgB,EAAED,IAAI,EAAEL,YAAY,CAAC;EAC5D;EACA;AACJ;AACA;AACA;AACA;EACI,SAASO,cAAcA,CAACC,eAAe,EAAE;IACrC;IACA,IAAInB,OAAO,CAACoB,sBAAsB,EAAE;MAChC,OAAOA,sBAAsB,CAACD,eAAe,CAAC;IAClD,CAAC,MACI;MACD;MACA,MAAME,gBAAgB,GAAGtB,KAAK,CAACuB,MAAM,CAACvB,KAAK,CAACwB,OAAO,CAACJ,eAAe,CAAC,CAAC;MACrE,OAAOE,gBAAgB;IAC3B;EACJ;EACA;AACJ;AACA;AACA;AACA;EACI,SAASD,sBAAsBA,CAACD,eAAe,EAAE;IAC7C;IACA,MAAMK,cAAc,GAAGL,eAAe,CAAC,CAAC,CAAC;MAAEM,qBAAqB,GAAGN,eAAe,CAACO,KAAK,CAAC,CAAC,CAAC;MAAEC,iBAAiB,GAAGC,gCAAgC,CAACJ,cAAc,EAAEC,qBAAqB,CAAC;IACxL;IACA,IAAIE,iBAAiB,EAAE;MACnB,MAAM,IAAIE,KAAK,CAAC/B,WAAW,CAACgC,MAAM,CAACC,QAAQ,CAACC,aAAa,CAAC;IAC9D;IACA,OAAOR,cAAc;EACzB;EACA;AACJ;AACA;EACI,SAASI,gCAAgCA,CAACJ,cAAc,EAAEC,qBAAqB,EAAE;IAC7E,OAAOA,qBAAqB,CAACQ,MAAM,CAAC,CAACN,iBAAiB,EAAEO,cAAc,KAAK;MACvE;MACA,MAAMC,mBAAmB,GAAGpC,KAAK,CAACqC,wBAAwB,CAACZ,cAAc,EAAEU,cAAc,CAAC,CAACG,MAAM;MACjG,OAAOF,mBAAmB,GAAG,CAAC,GACxBR,iBAAiB,GAAG,CAAC,GACrBA,iBAAiB;IAC3B,CAAC,EAAE,CAAC,CAAC;EACT;EACA;AACJ;AACA;EACI,SAASW,kBAAkBA,CAACC,QAAQ,EAAE;IAClC,IAAIvC,OAAO,CAACwC,WAAW,EAAE;MACrB,OAAOD,QAAQ,CAACE,MAAM,CAAEC,OAAO,IAAK;QAChC,OAAO,CAAC1C,OAAO,CAACwC,WAAW,CAACG,QAAQ,CAACD,OAAO,CAAC;MACjD,CAAC,CAAC;IACN;IACA,OAAOH,QAAQ;EACnB;EACA;AACJ;AACA;EACI,SAASK,gBAAgBA,CAACC,UAAU,EAAE;IAClC,IAAI7C,OAAO,CAAC8C,UAAU,IAAI,OAAO9C,OAAO,CAAC8C,UAAU,KAAK,UAAU,EAAE;MAChE,OAAOD,UAAU,CAACE,IAAI,CAAC/C,OAAO,CAAC8C,UAAU,CAAC;IAC9C,CAAC,MACI,IAAI9C,OAAO,CAAC8C,UAAU,EAAE;MACzB,OAAOD,UAAU,CAACE,IAAI,CAAC,CAAC;IAC5B;IACA,OAAOF,UAAU;EACrB;EACA;AACJ;AACA;EACI,SAASG,gBAAgBA,CAACC,MAAM,EAAE;IAC9B,IAAIjD,OAAO,CAACgD,gBAAgB,EAAE;MAC1BC,MAAM,CAACC,YAAY,GAAGD,MAAM,CAACC,YAAY,CAACC,GAAG,CAAEC,KAAK,IAAKA,KAAK,CAACC,KAAK,CAAC,GAAG,CAAC,CACpEF,GAAG,CAAEG,SAAS,IAAKA,SAAS,CAACC,IAAI,CAAC,CAAC,CAAC,CACpCC,IAAI,CAAC,GAAG,CAAC,CAAC;IACnB;IACA,OAAOP,MAAM;EACjB;EACA;AACJ;AACA;EACI,SAASQ,gBAAgBA,CAACR,MAAM,EAAE;IAC9B;IACA,IAAIjD,OAAO,CAAC0D,aAAa,EAAE;MACvBT,MAAM,CAACC,YAAY,GAAGD,MAAM,CAACC,YAAY,CAACC,GAAG,CAAC,UAAUQ,UAAU,EAAE;QAChE,OAAOC,yBAAyB,CAACD,UAAU,CAAC;MAChD,CAAC,CAAC;IACN;IACA,OAAOV,MAAM;EACjB;EACA;AACJ;AACA;EACI,SAASY,iBAAiBA,CAACZ,MAAM,EAAE;IAC/B;IACA,MAAMa,iBAAiB,GAAG7F,MAAM,CAAC8F,IAAI,CAAC/D,OAAO,CAACgE,aAAa,CAAC;IAC5Df,MAAM,CAACgB,MAAM,GAAGhB,MAAM,CAACC,YAAY,CAC9BC,GAAG,CAAC,UAAUC,KAAK,EAAE;MACtB,MAAMc,SAAS,GAAGJ,iBAAiB,CAACnB,QAAQ,CAACS,KAAK,CAAC,GAAGpD,OAAO,CAACgE,aAAa,CAACZ,KAAK,CAAC,GAAGA,KAAK;MAC1F,OAAOQ,yBAAyB,CAACM,SAAS,CAAC;IAC/C,CAAC,CAAC,CACGV,IAAI,CAACxD,OAAO,CAACG,SAAS,CAACiD,KAAK,CAAC;IAClC,OAAOH,MAAM;EACjB;EACA,SAASkB,yBAAyBA,CAAA,EAAG;IACjC,IAAI,CAACnE,OAAO,CAAC+D,IAAI,EACb,OAAO,EAAE;IACb,OAAO/D,OAAO,CAAC+D,IAAI,CAACZ,GAAG,CAAEiB,GAAG,IAAK;MAC7B,IAAI,OAAOA,GAAG,KAAK,QAAQ,IAAI,OAAO,IAAIA,GAAG,EAAE;QAC3CpE,OAAO,CAACgE,aAAa,CAACI,GAAG,CAAChB,KAAK,CAAC,GAAGgB,GAAG,CAACC,KAAK,IAAID,GAAG,CAAChB,KAAK;QACzD,OAAOgB,GAAG,CAAChB,KAAK;MACpB;MACA,OAAOgB,GAAG;IACd,CAAC,CAAC;EACN;EACA;AACJ;AACA;AACA;EACI,SAASE,oBAAoBA,CAACtD,IAAI,EAAE;IAChC,MAAMuD,UAAU,GAAGJ,yBAAyB,CAAC,CAAC;IAC9C,IAAInE,OAAO,CAAC+D,IAAI,EAAE;MACd/D,OAAO,CAAC+D,IAAI,GAAGQ,UAAU;MACzB,IAAI,CAACvE,OAAO,CAACU,YAAY,EAAE;QACvB,MAAM8D,QAAQ,GAAGlC,kBAAkB,CAACiC,UAAU,CAAC;QAC/C,OAAO3B,gBAAgB,CAAC4B,QAAQ,CAAC;MACrC;IACJ;IACA,MAAM3B,UAAU,GAAG9B,gBAAgB,CAACC,IAAI,CAAC;IACzC,MAAMyD,SAAS,GAAGvD,cAAc,CAAC2B,UAAU,CAAC;IAC5C,MAAM2B,QAAQ,GAAGlC,kBAAkB,CAACmC,SAAS,CAAC;IAC9C,OAAO7B,gBAAgB,CAAC4B,QAAQ,CAAC;EACrC;EACA;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;EACI,SAASE,wBAAwBA,CAACzB,MAAM,EAAE0B,SAAS,GAAG,KAAK,EAAE;IACzD,IAAI3E,OAAO,CAACU,YAAY,EAAE;MACtB,MAAMkE,qBAAqB,GAAG3B,MAAM,CAAC4B,OAAO,CAACxC,MAAM;MACnD;MACAY,MAAM,CAACC,YAAY,CAAC4B,OAAO,CAAEC,WAAW,IAAK;QACzC9B,MAAM,CAAC4B,OAAO,GAAG9E,KAAK,CAACiF,MAAM,CAAC/B,MAAM,CAAC4B,OAAO,EAAEE,WAAW,CAAC;MAC9D,CAAC,CAAC;MACF,MAAM7B,YAAY,GAAGoB,oBAAoB,CAACrB,MAAM,CAAC4B,OAAO,CAAC;MACzD5B,MAAM,CAACC,YAAY,GAAGA,YAAY;MAClC;MACA,IAAI0B,qBAAqB,KAAK3B,MAAM,CAAC4B,OAAO,CAACxC,MAAM,EAAE;QACjD,OAAOqC,wBAAwB,CAACzB,MAAM,CAAC;MAC3C;MACA;MACA;MACA;MACA,IAAI,CAAC0B,SAAS,EAAE;QACZ,OAAOD,wBAAwB,CAACzB,MAAM,EAAE,IAAI,CAAC;MACjD;MACA;MACA,IAAIjD,OAAO,CAAC+D,IAAI,EAAE;QACd,MAAMkB,kBAAkB,GAAGd,yBAAyB,CAAC,CAAC;QACtDlB,MAAM,CAACC,YAAY,GAAGZ,kBAAkB,CAAC2C,kBAAkB,CAAC;MAChE;MACA,OAAOhC,MAAM;IACjB;IACA,OAAOA,MAAM;EACjB;EACA;AACJ;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;EACI,SAASiC,cAAcA,CAACjC,MAAM,EAAE;IAC5BA,MAAM,CAACkC,YAAY,GAAGlC,MAAM,CAAC4B,OAAO,CAAC1B,GAAG,CAAEiC,MAAM,IAAK;MACjD;MACA,MAAMC,eAAe,GAAGC,uBAAuB,CAACF,MAAM,EAAEnC,MAAM,CAACC,YAAY,CAAC;QAC5E;QACAqC,mBAAmB,GAAGF,eAAe,CAAClC,GAAG,CAAEqC,UAAU,IAAK;UACtDA,UAAU,GAAGC,oBAAoB,CAACD,UAAU,CAAC;UAC7CA,UAAU,GAAGE,mBAAmB,CAACF,UAAU,CAAC;UAC5C,IAAIG,WAAW,GAAGrF,iBAAiB,GAAGA,iBAAiB,CAACkF,UAAU,EAAEI,wBAAwB,CAAC,GAAGA,wBAAwB,CAACJ,UAAU,CAAC;UACpIG,WAAW,GAAG/B,yBAAyB,CAAC+B,WAAW,CAAC;UACpD,OAAOA,WAAW;QACtB,CAAC,CAAC;MACF;MACA,OAAOE,wBAAwB,CAACN,mBAAmB,CAAC;IACxD,CAAC,CAAC,CAAC/B,IAAI,CAACxD,OAAO,CAACG,SAAS,CAAC2F,GAAG,CAAC;IAC9B,OAAO7C,MAAM;EACjB;EACA;AACJ;AACA;EACI,SAAS8C,4CAA4CA,CAACC,gBAAgB,EAAE;IACpE,MAAMC,wBAAwB,GAAGlG,KAAK,CAACmG,iBAAiB,CAACF,gBAAgB,CAAC;IAC1E;IACA,IAAI,CAACA,gBAAgB,CAAC3D,MAAM,IAAI,CAAC4D,wBAAwB,CAAC5D,MAAM,EAAE;MAC9D,OAAOrC,OAAO,CAACmG,eAAe,IAAI,EAAE;IACxC,CAAC,MACI,IAAIF,wBAAwB,CAAC5D,MAAM,KAAK,CAAC,EAAE;MAC5C;MACA;MACA,OAAO4D,wBAAwB,CAAC,CAAC,CAAC,CAAC,CAAC;IACxC;IACA,OAAOD,gBAAgB;EAC3B;EACA;AACJ;AACA;EACI,SAASV,uBAAuBA,CAACF,MAAM,EAAEgB,MAAM,EAAE;IAC7C,MAAMC,YAAY,GAAG,EAAE;IACvBD,MAAM,CAACtB,OAAO,CAAE1B,KAAK,IAAK;MACtB,IAAI4C,gBAAgB,GAAG,CAAC,CAAC,EAAErG,UAAU,CAAC2G,YAAY,EAAElB,MAAM,EAAEhC,KAAK,CAAC;MAClE,IAAI,CAACrD,KAAK,CAACwG,WAAW,CAACvG,OAAO,CAACmG,eAAe,CAAC,IAAIpG,KAAK,CAACyG,YAAY,CAACR,gBAAgB,CAAC,EAAE;QACrFA,gBAAgB,GAAGhG,OAAO,CAACmG,eAAe;MAC9C,CAAC,MACI,IAAInG,OAAO,CAACS,kBAAkB,IAAIgG,KAAK,CAACC,OAAO,CAACV,gBAAgB,CAAC,EAAE;QACpEA,gBAAgB,GAAGD,4CAA4C,CAACC,gBAAgB,CAAC;MACrF;MACAK,YAAY,CAACM,IAAI,CAACX,gBAAgB,CAAC;IACvC,CAAC,CAAC;IACF,OAAOK,YAAY;EACvB;EACA;AACJ;AACA;EACI,SAAST,wBAAwBA,CAACJ,UAAU,EAAE;IAC1C,MAAMoB,MAAM,GAAGpB,UAAU,YAAYqB,IAAI,CAAC,CAAC;IAC3C,IAAIrB,UAAU,KAAK,IAAI,IAAIiB,KAAK,CAACC,OAAO,CAAClB,UAAU,CAAC,IAAI,OAAOA,UAAU,KAAK,QAAQ,IAAI,CAACoB,MAAM,EAAE;MAC/F,OAAOE,IAAI,CAACC,SAAS,CAACvB,UAAU,CAAC;IACrC,CAAC,MACI,IAAI,OAAOA,UAAU,KAAK,WAAW,EAAE;MACxC,OAAO,WAAW;IACtB,CAAC,MACI,IAAIoB,MAAM,IAAI5G,OAAO,CAACgH,oBAAoB,EAAE;MAC7C,OAAOxB,UAAU,CAACyB,WAAW,CAAC,CAAC;IACnC,CAAC,MACI;MACD,OAAO,CAACjH,OAAO,CAACkH,eAAe,GAAG1B,UAAU,CAAC2B,QAAQ,CAAC,CAAC,GAAG3B,UAAU,CAAC4B,cAAc,CAAC,CAAC;IACzF;EACJ;EACA;AACJ;AACA;EACI,SAAS3B,oBAAoBA,CAACD,UAAU,EAAE;IACtC,IAAIxF,OAAO,CAACqH,eAAe,EAAE;MACzB,IAAIZ,KAAK,CAACC,OAAO,CAAClB,UAAU,CAAC,EAAE;QAC3B,OAAOA,UAAU,CAACrC,GAAG,CAACsC,oBAAoB,CAAC;MAC/C,CAAC,MACI,IAAI,OAAOD,UAAU,KAAK,QAAQ,EAAE;QACrC,OAAOA,UAAU,CAACjC,IAAI,CAAC,CAAC;MAC5B;MACA,OAAOiC,UAAU;IACrB;IACA,OAAOA,UAAU;EACrB;EACA;AACJ;AACA;AACA;AACA;AACA;EACI,SAASE,mBAAmBA,CAACF,UAAU,EAAE;IACrC,IAAIxF,OAAO,CAAC0F,mBAAmB,EAAE;MAC7B,IAAIe,KAAK,CAACC,OAAO,CAAClB,UAAU,CAAC,EAAE;QAC3B,OAAOA,UAAU,CAACrC,GAAG,CAACuC,mBAAmB,CAAC;MAC9C,CAAC,MACI,IAAI,OAAOF,UAAU,KAAK,QAAQ,IAAI,CAACzF,KAAK,CAACuH,QAAQ,CAAC9B,UAAU,CAAC,EAAE;QACpE,OAAOA,UAAU,CAAC+B,OAAO,CAAC,gBAAgB,EAAE,EAAE,CAAC;MACnD;MACA,OAAO/B,UAAU;IACrB;IACA,OAAOA,UAAU;EACrB;EACA;AACJ;AACA;AACA;AACA;EACI,SAAS5B,yBAAyBA,CAAC4B,UAAU,EAAE;IAC3C,MAAMgC,aAAa,GAAGxH,OAAO,CAACG,SAAS,CAACC,IAAI;IAC5C;IACA,IAAIoF,UAAU,CAAC7C,QAAQ,CAAC3C,OAAO,CAACG,SAAS,CAACC,IAAI,CAAC,EAAE;MAC7C;MACAoF,UAAU,GAAGA,UAAU,CAAC+B,OAAO,CAACtH,uBAAuB,EAAEuH,aAAa,GAAGA,aAAa,CAAC;IAC3F;IACA;IACA;IACA,IAAIhC,UAAU,CAAC7C,QAAQ,CAAC3C,OAAO,CAACG,SAAS,CAACiD,KAAK,CAAC,IAC5CoC,UAAU,CAAC7C,QAAQ,CAAC3C,OAAO,CAACG,SAAS,CAACC,IAAI,CAAC,IAC3CoF,UAAU,CAACiC,KAAK,CAACpH,eAAe,CAAC,IACjCL,OAAO,CAAC0H,YAAY,KAAKlC,UAAU,KAAK,MAAM,IAAIA,UAAU,KAAK,OAAO,CAAC,EAAE;MAC3E;MACAA,UAAU,GAAGgC,aAAa,GAAGhC,UAAU,GAAGgC,aAAa;IAC3D;IACA,OAAOhC,UAAU;EACrB;EACA;AACJ;AACA;EACI,SAASK,wBAAwBA,CAAC8B,iBAAiB,EAAE;IACjD,OAAOA,iBAAiB,CAACnE,IAAI,CAACxD,OAAO,CAACG,SAAS,CAACiD,KAAK,CAAC;EAC1D;EACA;EACA;AACJ;AACA;AACA;AACA;EACI,SAASwE,yBAAyBA,CAAC3E,MAAM,EAAE;IACvC,MAAMgB,MAAM,GAAGhB,MAAM,CAACgB,MAAM;MAAEY,OAAO,GAAG5B,MAAM,CAACkC,YAAY;MAC3D;MACA0C,GAAG,GAAG,CAAC7H,OAAO,CAAC8H,QAAQ,GAAGhI,WAAW,CAACgI,QAAQ,GAAG,EAAE,KAC9C9H,OAAO,CAAC0D,aAAa,GAAGO,MAAM,GAAGjE,OAAO,CAACG,SAAS,CAAC2F,GAAG,GAAG,EAAE,CAAC,GAC7DjB,OAAO;IACX,OAAOgD,GAAG;EACd;EACA;EACA;AACJ;AACA;EACI,SAASE,OAAOA,CAAC/G,IAAI,EAAE;IACnB;IACA,IAAIjB,KAAK,CAACiI,QAAQ,CAAChH,IAAI,CAAC,IAAI,CAACA,IAAI,CAACqB,MAAM,EAAE;MACtCrB,IAAI,GAAG,CAACA,IAAI,CAAC,CAAC,CAAC;IACnB;IACA;IACA,MAAMkC,YAAY,GAAG;MACjBA,YAAY,EAAEoB,oBAAoB,CAACtD,IAAI,CAAC;MACxC6D,OAAO,EAAE7D,IAAI;MACbiD,MAAM,EAAE,EAAE;MACVkB,YAAY,EAAE;IAClB,CAAC;IACD,MAAM8C,QAAQ,GAAGvD,wBAAwB,CAACxB,YAAY,CAAC;IACvD,MAAMuB,SAAS,GAAGS,cAAc,CAAC+C,QAAQ,CAAC;IAC1C,MAAMC,OAAO,GAAGzE,gBAAgB,CAACgB,SAAS,CAAC;IAC3C,MAAM0D,OAAO,GAAGnF,gBAAgB,CAACkF,OAAO,CAAC;IACzC,MAAME,SAAS,GAAGvE,iBAAiB,CAACsE,OAAO,CAAC;IAC5C,OAAOP,yBAAyB,CAACQ,SAAS,CAAC;EAC/C;EACA,OAAO;IACHL;EACJ,CAAC;AACL,CAAC;AACDtI,OAAO,CAACC,QAAQ,GAAGA,QAAQ"},"metadata":{},"sourceType":"script","externalDependencies":[]}